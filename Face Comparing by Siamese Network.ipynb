{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Comparing by Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Imaging Library\n",
    "from PIL import Image    \n",
    "import PIL.ImageOps\n",
    "\n",
    "# Packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset       #https://zhuanlan.zhihu.com/p/30934236\n",
    "from torch import optim     # 包含optimization algorithms\n",
    "import torch.nn.functional as F     # 包含activation functions\n",
    "from torch.autograd import Variable      # 以Variable形式嵌套激励函数 \n",
    "import torch.nn as nn\n",
    "\n",
    "# Torchvision 包含目前流行的数据集，模型结构和常用的图片转换工具等\n",
    "import torchvision\n",
    "import torchvision.datasets as dset    # 数据集\n",
    "import torchvision.transforms as transforms  # 可对PIL.Image, Tensor进行变换\n",
    "import torchvision.utils  ##\n",
    "\n",
    "# Others\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出图的功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None, should_save=False):     #数据集出图\n",
    "    npimg = img.numpy() \n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic', fontweight='bold',\n",
    "                bbox={'facecolor':'white','alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "        \n",
    "def show_plot(iteration, loss):                    #观察迭代损失\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径与参数的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"./Datasets/att/training/\"\n",
    "    validation_dir = \"./Datasets/att/validamulti\"\n",
    "    testing_dir = \"./Datasets/att/testing/\"\n",
    "    train_batch_size = 32           #批样本数\n",
    "    train_number_epoch = 100     #整批训练次数，即遍历了多少次所有的训练样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练集数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 for Anchor-Positive pairs, 1 for Anchor-Negative pairs.  训练集数据须注意数据的均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)   #在self...imgs中返回随机项\n",
    "        # 数据均衡，等概率取A-P对和A-N对\n",
    "        should_get_same_class = random.randint(0,1)    # 随机返回0，1\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                # 需要A-P对，保持循环，直到找到相同的类的图像\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs)   #元组=（图片路径，类编号）\n",
    "                if img0_tuple[1] == img1_tuple[1]:                         #图片编号相同则是同一个类（即文件夹）\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                # 需要A-N对，同样循环，保证两个图像的类不同\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "                if img0_tuple[1] != img1_tuple[1]:                         #图片编号相同则是同一个类（即文件夹）\n",
    "                    break                \n",
    "            \n",
    "        img0 = Image.open(img0_tuple[0])    #读取实际图像，tuple[0]即路径\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img0 = img0.convert(\"L\")            #from PIL，把img转换为256级灰度图像， L：8-bit pixels,black and white\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)    #可将输入图像转换为反色图像\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            \n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])], dtype=np.float32))\n",
    "            #返回 img0,img1,以及二者的类别（0或1），完成数据组对\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)          #数据集大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                     transforms.ToTensor()\n",
    "                                                                     ]) #compose将“transforms”组合\n",
    "                                        ,should_invert=False)\n",
    "\n",
    "# ImageFolder: pytorch.org/docs/master/torchvision/datasets.html#imagefolder\n",
    "# transforms: http://pytorch.org/docs/master/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部分数据可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各列首末为一对，0列相似，1列不相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(dataset=siamese_dataset,\n",
    "                           shuffle=True,    #每个epoch打乱顺序\n",
    "                           num_workers=2,   #加载数据的子进程数\n",
    "                           batch_size=8)    #每批加载的样本数\n",
    "data_iter = iter(vis_dataloader)    #生成迭代器\n",
    "\n",
    "example_batch = next(data_iter)     #返回迭代器的下一个项目\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)  #张量拼接，0：按行，1：按列\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())\n",
    "\n",
    "## DataLoader: http://pytorch.org/docs/master/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用标准的cnn结构。在每个卷积层后进行批标准化。网络接受一个100px* 100px的输入。在卷积层后有三个全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):                 # torch.nn.Module:所有神经网络模块的基类\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(               # torch.nn.Sequential:模块将按照在构造器中的顺序传递\n",
    "            nn.ReflectionPad2d(1),               # 使用输入边界的反射来填充输入张量\n",
    "            nn.Conv2d(                           # 对信号（由若干输入平面组成）进行2维卷积\n",
    "                in_channels=1,                   # input height. 灰度图1层，RGB为3层，即图像的通道数\n",
    "                out_channels=4,                  # n_filters 过滤器数目，过滤器提取的特征数\n",
    "                kernel_size=3,                   # 卷积核 filter size 3x3\n",
    "                stride=1,                        # filter movement/step 跳度\n",
    "                padding=0,                       # 若想要con2d出来的图片长宽没有变化，当stride=1,padding=(kernel_size-1)/2\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),               # ReLU(x)=max(0,x)\n",
    "            nn.BatchNorm2d(4),                   # 对4维输入应用批标准化（一个小批量的2维输入和额外的通道尺寸）\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(\n",
    "                in_channels=4,\n",
    "                out_channels=8,\n",
    "                kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(                   # fc\n",
    "            nn.Linear(in_features=8*100*100,        # 线性层,y=Ax+b\n",
    "                      out_features=500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500,500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500,5)\n",
    "    )\n",
    "    \n",
    "    def forward_once(self,x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0],-1)   #展平多维的卷积图。http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('sia_att_params.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\" \n",
    "    \n",
    "    def __init__(self,margin=0.2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, output1, output2, label):\n",
    "        eu_distance = F.pairwise_distance(output1, output2)         #euclidean distance\n",
    "        loss_contrastive = torch.mean( (1-label) * torch.pow(eu_distance, 2) + \n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - eu_distance, min=0.0),2) )\n",
    "        \n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2,\n",
    "                             batch_size=Config.train_batch_size)\n",
    "\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr =0.00001)         #Adam优化所有参数，学习率=0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = []\n",
    "iteration_number = 0      #初始化迭代次数（更新了多少次参数的值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(0, Config.train_number_epoch):\n",
    "    for i, data in enumerate(train_dataloader, 0):   #将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "        img0, img1, label = data\n",
    "        img0, img1, label = Variable(img0), Variable(img1), Variable(label)\n",
    "        output1, output2 = net(img0, img1)   # network output\n",
    "        optimizer.zero_grad()      # clear gradients for this training step\n",
    "        loss_contrastive = criterion(output1, output2, label)  #计算loss\n",
    "        loss_contrastive.backward()    #backprop, 计算梯度\n",
    "        optimizer.step()                #apply gradients        \n",
    "\n",
    "        if i%10 == 0:\n",
    "            print(\"Epoch: {} | Current Loss {}\\n\".format(epoch, loss_contrastive.data[0]))\n",
    "            iteration_number += 10\n",
    "            counter.append(iteration_number)   \n",
    "            loss_history.append(loss_contrastive.data[0])\n",
    "    \n",
    "    torch.save(net.state_dict(),'sia_lfwa_params_vt.pkl')\n",
    "    \n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'sia_att_params_vt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察训练集数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_train_distri = dset.ImageFolder(root=Config.training_dir)\n",
    "siamese_train_distri = SiameseNetworkDataset(imageFolderDataset=folder_train_distri,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "train_distri_dataloader = DataLoader(siamese_train_distri,\n",
    "                             num_workers=8,\n",
    "                             batch_size=1,\n",
    "                             shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "same_one_train = np.array([])\n",
    "diff_one_train = np.array([])\n",
    "label_1 = np.array([1.0])\n",
    "label_0 = np.array([0.0])\n",
    "\n",
    "for i, data in enumerate(train_distri_dataloader, 0):   #将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "    img0, img1, label = data\n",
    "    img0, img1, label = Variable(img0), Variable(img1), Variable(label)\n",
    "    output1, output2 = net(img0, img1)   # network output\n",
    "    eu_distance = F.pairwise_distance(output1, output2)\n",
    "    eu_dist = eu_distance.cpu().data.numpy()[0][0]\n",
    "    label_num = label.cpu().data.numpy()[0][0]    \n",
    "    if (label_num == label_0).all():    #a \"numpy way\"\n",
    "        same_one_train = np.append(same_one_train, eu_dist)\n",
    "    else:\n",
    "        diff_one_train = np.append(diff_one_train, eu_dist)    \n",
    "\n",
    "            \n",
    "sns.distplot(same_one_train, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from same classes')\n",
    "sns.distplot(diff_one_train, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from different classes')\n",
    "plt.xlabel('Dissimilarity(Euclidean Distance)')\n",
    "plt.ylabel('Relative quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察验证集数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_valida_distri = dset.ImageFolder(root=Config.validation_dir)\n",
    "siamese_valida_distri = SiameseNetworkDataset(imageFolderDataset=folder_valida_distri,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "valida_distri_dataloader = DataLoader(siamese_valida_distri,\n",
    "                             num_workers=8,\n",
    "                             batch_size=1,\n",
    "                             shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "same_one_valida = np.array([])\n",
    "diff_one_valida = np.array([])\n",
    "label_1 = np.array([1.0])\n",
    "label_0 = np.array([0.0])\n",
    "\n",
    "for i, data in enumerate(valida_distri_dataloader, 0):   #将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "    img0, img1, label = data\n",
    "    img0, img1, label = Variable(img0), Variable(img1), Variable(label)\n",
    "    output1, output2 = net(img0, img1)   # network output\n",
    "    eu_distance = F.pairwise_distance(output1, output2)\n",
    "    eu_dist = eu_distance.cpu().data.numpy()[0][0]\n",
    "    label_num = label.cpu().data.numpy()[0][0]    \n",
    "    if (label_num == label_0).all():    #a \"numpy way\"\n",
    "        same_one_valida = np.append(same_one_valida, eu_dist)\n",
    "    else:\n",
    "        diff_one_valida = np.append(diff_one_valida, eu_dist)    \n",
    "\n",
    "            \n",
    "\n",
    "sns.distplot(same_one_valida, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from same classes')\n",
    "sns.distplot(diff_one_valida, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from different classes')\n",
    "plt.xlabel('Dissimilarity(Euclidean Distance)')\n",
    "plt.ylabel('Relative Quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_array = np.array([])\n",
    "fpr_array = np.array([])\n",
    "same_one_valida = np.array([])\n",
    "diff_one_valida = np.array([])\n",
    "label_1 = np.array([1.0])\n",
    "label_0 = np.array([0.0])\n",
    "\n",
    "\n",
    "for thres in range(0,5,1):\n",
    "    print(thres)\n",
    "    tpm = 0\n",
    "    fpm = 0\n",
    "    tp_fn = 0\n",
    "    fp_tn = 0\n",
    "    for i, data in enumerate(valida_distri_dataloader, 0):\n",
    "        img0, img1, label = data\n",
    "        img0, img1, label = Variable(img0), Variable(img1), Variable(label)\n",
    "        output1, output2 = net(img0, img1)   # network output\n",
    "        eu_distance = F.pairwise_distance(output1, output2)\n",
    "        eu_dist = eu_distance.cpu().data.numpy()[0][0]\n",
    "        label_num = label.cpu().data.numpy()[0][0]\n",
    "        if (label_num == label_0).all():\n",
    "            tp_fn = tp_fn + 1\n",
    "        else:\n",
    "            fp_tn = fp_tn + 1\n",
    "        if eu_dist < (thres/10):\n",
    "            if (label_num == label_0).all():    #a \"numpy way\"\n",
    "                tpm = tpm + 1\n",
    "#                 print('tpm={},tp_fn={},thres={}'.format(tpm,tp_fn,(thres/10)))\n",
    "            else:\n",
    "                fpm = fpm + 1\n",
    "#                 print('fpm={},fp_tn={},thres={}'.format(fpm,fp_tn,(thres/10)))\n",
    "        \n",
    "    try:\n",
    "        tpr=tpm/tp_fn\n",
    "    except:\n",
    "        print(\"still 0\")\n",
    "    else:\n",
    "        tpr_array = np.append(tpr_array,tpr)\n",
    "    try:\n",
    "        fpr=fpm/fp_tn\n",
    "    except:\n",
    "        print(\"still 0\")\n",
    "    else:\n",
    "        fpr_array = np.append(fpr_array,fpr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp_fn,fp_tn,tpm,fpm)\n",
    "len(fpr_array)\n",
    "x = fpr_array\n",
    "y = tpr_array \n",
    "sia_adam_roc = (x,y)\n",
    "sia_adam_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sia_adam_roc.npy\",sia_adam_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_adam_roc = np.load(\"sia_adam_roc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sia_adam_roc[0]\n",
    "y = sia_adam_roc[1]\n",
    "\n",
    "# This is the ROC curve\n",
    "plt.plot(x,y,'+')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# This is the AUC\n",
    "auc = np.trapz(y,x)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4组数据作为数据集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "threshold = 0.135\n",
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "siamese_dataset_test = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset_test,\n",
    "                             num_workers=1,\n",
    "                             batch_size=1,\n",
    "                             shuffle=True)\n",
    "dataiter = iter(test_dataloader)\n",
    "x0,_,_ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    x0, x1, label2 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "    output1, output2 = net(Variable(x0), Variable(x1))     #Variable(x0).cuda()\n",
    "    eu_distance = F.pairwise_distance(output1, output2)\n",
    "    eu_dist = eu_distance.cpu().data.numpy()[0][0]\n",
    "    if eu_dist <= threshold:\n",
    "        imshow(torchvision.utils.make_grid(concatenated),\n",
    "           'Dissimilarity:{:.2f}\\nSame One!'.format(eu_dist))\n",
    "    else:\n",
    "        imshow(torchvision.utils.make_grid(concatenated),\n",
    "           'Dissimilarity:{:.2f}\\nDifferent Ones!'.format(eu_dist)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入特定两幅人脸图片进行比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('L')\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPair(Dataset):\n",
    "    def __init__(self, path_a, path_b, data_transforms=None, loader = default_loader):\n",
    "        self.path_a = path_a\n",
    "        self.path_b = path_b  \n",
    "        self.data_transforms = data_transforms\n",
    "        self.loader = loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_a)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_a = self.loader(path_a)\n",
    "        img_b = self.loader(path_b)\n",
    "        \n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                img_a = self.data_transforms(img_a)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_a))\n",
    "            try:\n",
    "                img_b = self.data_transforms(img_b)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_s))\n",
    "\n",
    "                \n",
    "        return img_a, img_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SiameseSoftware(path_a, path_b):\n",
    "    threshold = 0.135\n",
    "    try_datasets = DataPair(path_a = path_a, \n",
    "                             path_b = path_b,\n",
    "                             data_transforms=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                         transforms.ToTensor()\n",
    "                                                                         ]),\n",
    "                                 )\n",
    "    try_dataloaders = DataLoader(try_datasets,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False)\n",
    "    dataiter = iter(try_dataloaders)\n",
    "    x0,_ = next(dataiter)\n",
    "\n",
    "    x0, x1 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "    output1, output2 = net(Variable(x0), Variable(x1))     #Variable(x0).cuda()\n",
    "    eu_distance = F.pairwise_distance(output1, output2)\n",
    "    eu_dist = eu_distance.cpu().data.numpy()[0][0]\n",
    "    if eu_dist <= threshold:\n",
    "        imshow(torchvision.utils.make_grid(concatenated),\n",
    "           'Dissimilarity:{:.2f}\\nSame One!'.format(eu_dist))\n",
    "    else:\n",
    "        imshow(torchvision.utils.make_grid(concatenated),\n",
    "           'Dissimilarity:{:.2f}\\nDifferent Ones!'.format(eu_dist))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path_a = './Datasets/att/validation/s32/2.png'      #输入图片路径\n",
    "path_b = './Datasets/att/validation/s32/7.png'\n",
    "SiameseSoftware(path_a, path_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
