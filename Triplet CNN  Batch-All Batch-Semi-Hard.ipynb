{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet CNN Batch-All/Batch-Semi-Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Imaging Library\n",
    "from PIL import Image    \n",
    "import PIL.ImageOps\n",
    "\n",
    "# Packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import optim     # 包含optimization algorithms\n",
    "import torch.nn.functional as F     # 包含activation functions\n",
    "from torch.autograd import Variable      # 以Variable形式嵌套激励函数 \n",
    "import torch.nn as nn\n",
    "\n",
    "# Torchvision 包含目前流行的数据集，模型结构和常用的图片转换工具等\n",
    "import torchvision\n",
    "import torchvision.datasets as dset    # 包含一些数据集\n",
    "import torchvision.transforms as transforms  # 可对PIL.Image, Tensor进行变换\n",
    "import torchvision.utils\n",
    "\n",
    "# Others\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import linecache\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"./Datasets/att/training/\"\n",
    "    validation_dir = \"./Datasets/att/validation\"\n",
    "    testing_dir = \"./Datasets/att/testing/\"\n",
    "    batch_apn_path = './batch_apn_forall.txt'\n",
    "    batch_all_hard_path = 'batch_all_hard.txt'\n",
    "    train_batch_size = 32           #批样本数\n",
    "    train_number_epoch = 400     #整批训练次数，即遍历了多少次所有的训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None, should_save=False):     #数据集出图\n",
    "    npimg = img.numpy()   #转numpy\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic', fontweight='bold',\n",
    "                bbox={'facecolor':'white','alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "        \n",
    "def show_plot(iteration, loss):                    #观察迭代损失\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchAllTriplets(data_path, batch_path, num_class, num_pic):\n",
    "    name_list = os.listdir(data_path)\n",
    "    batch_name = random.sample(name_list, num_class)\n",
    "    batch_name.sort()\n",
    "    print(batch_name)\n",
    "    batch_apn = []\n",
    "    for k in range(len(batch_name)):\n",
    "        name = batch_name[k]\n",
    "        path1 = data_path + name + '/'\n",
    "        pic_list1 = os.listdir(path1)\n",
    "        batch_pic1 = random.sample(pic_list1, num_pic)\n",
    "        batch_pic1.sort()                       #sort pics in the batch\n",
    "        for i in range(len(batch_pic1)):\n",
    "            anchor_pic = batch_pic1[i]\n",
    "            anchor_pic = path1 + anchor_pic\n",
    "            for j in range(len(batch_pic1)):\n",
    "                if i!= j:\n",
    "                    positive_pic = batch_pic1[j]\n",
    "                    positive_pic = path1 + positive_pic\n",
    "                    pic_ap = anchor_pic + '\\t' + positive_pic    #make ap pairs per pic\n",
    "                    for v in range(len(batch_name)):\n",
    "                        name_other = batch_name[v]\n",
    "                        path2 = data_path + name_other + '/'\n",
    "                        pic_list2 = os.listdir(path2)\n",
    "                        batch_pic2 = random.sample(pic_list2, num_pic)\n",
    "                        batch_pic2.sort()\n",
    "                        if v != k:\n",
    "                            for q in range(len(batch_pic2)):\n",
    "                                negative_pic = batch_pic2[q]\n",
    "                                negative_pic = path2 + negative_pic\n",
    "                                pic_apn = pic_ap + '\\t' + negative_pic\n",
    "                                batch_apn.append(pic_apn)\n",
    "    fileObject = open(Config.batch_apn_path, 'w')  \n",
    "    for pic_apn in batch_apn:  \n",
    "        fileObject.write(pic_apn)  \n",
    "        fileObject.write('\\n')  \n",
    "    fileObject.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_batch_size = 4\n",
    "pic_batch_size = 5\n",
    "\n",
    "MiniBatchAllTriplets(data_path = Config.training_dir, \n",
    "                     batch_path = Config.batch_apn_path,\n",
    "                     num_class = class_batch_size,\n",
    "                     num_pic = pic_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('L')\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetBatchTriplet(Dataset):\n",
    "    def __init__(self, img_path, txt_path, data_transforms=None, loader = default_loader):\n",
    "        with open(txt_path) as input_file1:\n",
    "            lines = input_file1.readlines()\n",
    "            self.img_anchor = [os.path.join(img_path, line.strip().split('\\t')[0]) for line in lines]\n",
    "            self.img_positi = [os.path.join(img_path, line.strip().split('\\t')[1]) for line in lines]   \n",
    "            self.img_negati = [os.path.join(img_path, line.strip().split('\\t')[2]) for line in lines]   \n",
    "        self.data_transforms = data_transforms\n",
    "        self.loader = loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_anchor)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_anchor = self.img_anchor[item]\n",
    "        img_positi = self.img_positi[item]\n",
    "        img_negati = self.img_negati[item]\n",
    "        img_a = self.loader(img_anchor)\n",
    "        img_p = self.loader(img_positi)\n",
    "        img_n = self.loader(img_negati)\n",
    "        \n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                img_a = self.data_transforms(img_a)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_a))\n",
    "            try:\n",
    "                img_p = self.data_transforms(img_p)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_s))\n",
    "            try:\n",
    "                img_n = self.data_transforms(img_n)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_h))    \n",
    "                \n",
    "        return img_a, img_p, img_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetwork(nn.Module):                 # torch.nn.Module:所有神经网络模块的基类\n",
    "    def __init__(self):\n",
    "        super(TripletNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(               # torch.nn.Sequential:模块将按照在构造器中的顺序传递\n",
    "            nn.ReflectionPad2d(1),               # 使用输入边界的反射来填充输入张量\n",
    "            nn.Conv2d(                           # 对信号（由若干输入平面组成）进行2维卷积\n",
    "                in_channels=1,                   # input height. 灰度图1层，RGB为3层，即图像的通道数\n",
    "                out_channels=4,                  # n_filters 过滤器数目，过滤器提取的特征数\n",
    "                kernel_size=3,                   # 卷积核 filter size 3x3\n",
    "                stride=1,                        # filter movement/step 跳度\n",
    "                padding=0,                       # 零填充。若想要con2d出来的图片长宽没有变化，当stride=1,padding=(kernel_size-1)/2\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),               # inplace不是很懂\n",
    "            nn.BatchNorm2d(4),                   # 对4维输入应用批标准化（一个小批量的2维输入和额外的通道尺寸）\n",
    "            nn.Dropout2d(p=.2),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(\n",
    "                in_channels=4,\n",
    "                out_channels=8,\n",
    "                kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "            \n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(                   # fc full connected\n",
    "            nn.Linear(in_features=8*100*100,        # 线性层,y=Ax+b\n",
    "                      out_features=500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500,500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500,50)\n",
    "    )\n",
    "    \n",
    "    def forward_once(self,x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0],-1)   #Morvan说是展平多维的卷积图。check:http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2, input3):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        output3 = self.forward_once(input3)\n",
    "        return output1,output2,output3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TripletNetwork()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = F.triplet_margin_loss()   \n",
    "# criterion = nn.TripletMarginLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "counter = []\n",
    "loss_history = [] \n",
    "valid_num = []\n",
    "iteration_number= 0\n",
    "batch_apn_path = Config.batch_apn_path\n",
    "batch_all_hard_path = Config.batch_all_hard_path\n",
    "class_batch_size = 5\n",
    "pic_batch_size = 5\n",
    "\n",
    "alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,Config.train_number_epoch):\n",
    "\n",
    "##筛选有效三元组（all or semi-hard）\n",
    "    batch_all_hard = []\n",
    "    MiniBatchAllTriplets(data_path = Config.training_dir,  \n",
    "                         batch_path = batch_apn_path,  \n",
    "                         num_class = class_batch_size,\n",
    "                         num_pic = pic_batch_size)\n",
    "    batch_apn_datasets = GetBatchTriplet(img_path='./',\n",
    "                                         txt_path=batch_apn_path,\n",
    "                                         data_transforms=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                             transforms.ToTensor()\n",
    "                                                                            ])\n",
    "                                         )\n",
    "    gethard_apn_dataloader = DataLoader(batch_apn_datasets,\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=1)\n",
    "    for i, data in enumerate(gethard_apn_dataloader,0):\n",
    "        img0, img1 , img2 = data\n",
    "        img0, img1 , img2 = Variable(img0), Variable(img1) , Variable(img2)\n",
    "        output1,output2,output3 = net(img0,img1,img2)\n",
    "        ## Semi-hard:\n",
    "        ###    [f(a)?f(p)]^2  <  [f(a)?f(n)]^2 \n",
    "        eu_distance_ap = F.pairwise_distance(output1, output2)\n",
    "        eu_distance_an = F.pairwise_distance(output1, output3)\n",
    "        eu_dist_ap = eu_distance_ap.cpu().data.numpy()[0][0]\n",
    "        eu_dist_an = eu_distance_an.cpu().data.numpy()[0][0]\n",
    "        eu_dist_ap_2 = eu_dist_ap**2\n",
    "        eu_dist_an_2 = eu_dist_an**2\n",
    "        if  (eu_dist_an_2 < eu_dist_ap_2 + alpha):      #batch-all\n",
    "#         if (eu_dist_ap_2 < eu_dist_an_2 and eu_dist_an_2 < eu_dist_ap_2 + alpha):          ##batch-semi-hard\n",
    "            linecache.updatecache(batch_apn_path)\n",
    "            all_apn_path = linecache.getline(batch_apn_path,i+1)\n",
    "            batch_all_hard.append(all_apn_path)\n",
    "    \n",
    "    \n",
    "    if batch_all_hard != []:\n",
    "        print(\"Valid Triplet: {} \\n\".format(len(batch_all_hard)))\n",
    "        list.append(valid_num,len(batch_all_hard))\n",
    "        fileObject = open(batch_all_hard_path, 'w')\n",
    "        for all_apn_path in batch_all_hard:\n",
    "            fileObject.write(all_apn_path)  \n",
    "    #       fileObject.write('\\n')  \n",
    "        fileObject.close()\n",
    "\n",
    "    \n",
    "    #### Training!\n",
    "        batch_all_hard_datasets = GetBatchTriplet(img_path='./',\n",
    "                                                  txt_path= batch_all_hard_path,\n",
    "                                                  data_transforms=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                                      transforms.ToTensor()\n",
    "                                                                                 ])\n",
    "                                              )\n",
    "\n",
    "        all_hard_dataloaders = DataLoader(batch_all_hard_datasets,\n",
    "                                           batch_size=32,\n",
    "                                           num_workers=4,\n",
    "                                           shuffle=True)\n",
    "\n",
    "        for i, data in enumerate(all_hard_dataloaders,0):\n",
    "            img0, img1 , img2 = data\n",
    "            img0, img1 , img2 = Variable(img0), Variable(img1) , Variable(img2)\n",
    "            output1,output2,output3 = net(img0,img1,img2)\n",
    "            optimizer.zero_grad()\n",
    "            loss_triplet = F.triplet_margin_loss(output1,output2,output3,margin=alpha)\n",
    "            loss_triplet.backward()\n",
    "            optimizer.step()\n",
    "            if i %10 == 0 :\n",
    "                print(\"Epoch: {} | Current loss {}\\n\".format(epoch,loss_triplet.data[0]))\n",
    "                iteration_number +=10\n",
    "                counter.append(iteration_number)\n",
    "                loss_history.append(loss_triplet.data[0])\n",
    "        \n",
    "    else:\n",
    "        print(\"Epoch:{}. Got no valid triplet in this batch\".format(epoch))\n",
    "     \n",
    "    torch.save(net.state_dict(),'tri_batch_all_params.pkl')\n",
    "    \n",
    "show_plot(counter,loss_history)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_num)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('valid triplets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'tri_batch_all_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('tri_batch_all_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)   #在self...imgs中返回随机项\n",
    "        # 先取A-P对，保持循环，直到找到相同的类的图像\n",
    "        while True:\n",
    "            img1_tuple = random.choice(self.imageFolderDataset.imgs)   #元组=（图片路径，类编号）\n",
    "            if img0_tuple[1] == img1_tuple[1]:                         #图片编号相同则是同一个类（以文件夹区分）\n",
    "                break\n",
    "        # 再取A-N\n",
    "        while True:\n",
    "            img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "            if img0_tuple[1] != img2_tuple[1]:\n",
    "                break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])    #读取实际图像，tuple[0]即路径\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img2 = Image.open(img2_tuple[0])\n",
    "        img0 = img0.convert(\"L\")            #from PIL，把img转换为256级灰度图像， L：8-bit pixels,black and white\n",
    "        img1 = img1.convert(\"L\")\n",
    "        img2 = img2.convert(\"L\")\n",
    "\n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)    #将输入图像转换为反色图像\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "            img2 = PIL.ImageOps.invert(img2)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            \n",
    "        return img0, img1, img2\n",
    "            #返回 img0,img1,img2，完成A-P-N组合\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)          #数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)   #在self...imgs中返回随机项\n",
    "        # 先取A-P对，保持循环，直到找到相同的类的图像\n",
    "        while True:\n",
    "            img1_tuple = random.choice(self.imageFolderDataset.imgs)   #元组=（图片路径，类编号）\n",
    "            if img0_tuple[1] == img1_tuple[1]:                         #图片编号相同则是同一个类（以文件夹区分）\n",
    "                break\n",
    "        # 再取A-N\n",
    "        while True:\n",
    "            img2_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "            if img0_tuple[1] != img2_tuple[1]:\n",
    "                break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])    #读取实际图像，tuple[0]即路径\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img2 = Image.open(img2_tuple[0])\n",
    "        img0 = img0.convert(\"L\")            #from PIL，把img转换为256级灰度图像， L：8-bit pixels,black and white\n",
    "        img1 = img1.convert(\"L\")\n",
    "        img2 = img2.convert(\"L\")\n",
    "\n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)    #将输入图像转换为反色图像\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "            img2 = PIL.ImageOps.invert(img2)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            \n",
    "        return img0, img1, img2\n",
    "            #返回 img0,img1,img2，完成A-P-N组合\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)          #数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_train = dset.ImageFolder(root=Config.training_dir)\n",
    "triplet_dataset = TripletNetworkDataset(imageFolderDataset=folder_dataset_train,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "train_distri_dataloader = DataLoader(triplet_dataset, \n",
    "                             num_workers=6, \n",
    "                             batch_size=1, \n",
    "                             shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "same_one_train = np.array([])\n",
    "diff_one_train = np.array([])\n",
    "\n",
    "\n",
    "for i, data in enumerate(train_distri_dataloader, 0):   #将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "    img0, img1, img3 = data\n",
    "    img0, img1, img3 = Variable(img0), Variable(img1), Variable(img3)\n",
    "    output1, output2, output3 = net(img0, img1,img3)   # network output\n",
    "    eu_distance_same = F.pairwise_distance(output1, output2)\n",
    "    eu_dist_same = eu_distance_same.cpu().data.numpy()[0][0]\n",
    "    eu_distance_diff = F.pairwise_distance(output1, output3)\n",
    "    eu_dist_diff = eu_distance_diff.cpu().data.numpy()[0][0]\n",
    "    same_one_train = np.append(same_one_train, eu_dist_same)\n",
    "    diff_one_train = np.append(diff_one_train, eu_dist_diff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(same_one_train, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from same classes')\n",
    "sns.distplot(diff_one_train, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from different classes')\n",
    "plt.xlabel('Dissimilarity(Euclidean Distance)')\n",
    "plt.ylabel('Relative quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_valida = dset.ImageFolder(root=Config.validation_dir)\n",
    "triplet_dataset = TripletNetworkDataset(imageFolderDataset=folder_dataset_valida,\n",
    "                                       transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "valida_distri_dataloader = DataLoader(triplet_dataset, \n",
    "                             num_workers=6, \n",
    "                             batch_size=1, \n",
    "                             shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "same_one_valida = np.array([])\n",
    "diff_one_valida= np.array([])\n",
    "\n",
    "\n",
    "for i, data in enumerate(valida_distri_dataloader, 0):   #将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "    img0, img1, img3 = data\n",
    "    img0, img1, img3 = Variable(img0), Variable(img1), Variable(img3)\n",
    "    output1, output2, output3 = net(img0, img1,img3)   # network output\n",
    "    eu_distance_same = F.pairwise_distance(output1, output2)\n",
    "    eu_dist_same = eu_distance_same.cpu().data.numpy()[0][0]\n",
    "    eu_distance_diff = F.pairwise_distance(output1, output3)\n",
    "    eu_dist_diff = eu_distance_diff.cpu().data.numpy()[0][0]\n",
    "    same_one_valida = np.append(same_one_valida, eu_dist_same)\n",
    "    diff_one_valida = np.append(diff_one_valida, eu_dist_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(same_one_valida, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from same classes')\n",
    "sns.distplot(diff_one_valida, \n",
    "             #bins=20, \n",
    "             rug=False, \n",
    "             hist=True,\n",
    "            label='Samples from different classes')\n",
    "plt.xlabel('Dissimilarity(Euclidean Distance)')\n",
    "plt.ylabel('Relative quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_array = np.array([])\n",
    "fpr_array = np.array([])\n",
    "same_one_valida = np.array([])\n",
    "diff_one_valida = np.array([])\n",
    "\n",
    "\n",
    "for thres in range(0,600,1):\n",
    "    print(thres)\n",
    "    tpm = 0\n",
    "    fpm = 0\n",
    "    tp_fn = 0\n",
    "    fp_tn = 0\n",
    "    for i, data in enumerate(valida_distri_dataloader, 0):\n",
    "        img0, img1, img2 = data\n",
    "        img0, img1, img2 = Variable(img0), Variable(img1), Variable(img2)\n",
    "        output1, output2, output3 = net(img0, img1, img2)   # network output\n",
    "        eu_distance_ap = F.pairwise_distance(output1, output2)\n",
    "        eu_dist_ap = eu_distance_ap.cpu().data.numpy()[0][0]\n",
    "        eu_distance_an = F.pairwise_distance(output1, output3)\n",
    "        eu_dist_an = eu_distance_an.cpu().data.numpy()[0][0]\n",
    "        \n",
    "        tp_fn = tp_fn + 1\n",
    "        fp_tn = fp_tn + 1\n",
    "        \n",
    "        if eu_dist_ap < (thres/100):\n",
    "            tpm = tpm + 1\n",
    "            \n",
    "        if eu_dist_an < (thres/100):\n",
    "            fpm = fpm + 1\n",
    "\n",
    "    try:\n",
    "        tpr=tpm/tp_fn\n",
    "    except:\n",
    "        print(\"still 0\")\n",
    "    else:\n",
    "        tpr_array = np.append(tpr_array,tpr)\n",
    "    try:\n",
    "        fpr=fpm/fp_tn\n",
    "    except:\n",
    "        print(\"still 0\")\n",
    "    else:\n",
    "        fpr_array = np.append(fpr_array,fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp_fn,fp_tn,tpm,fpm)\n",
    "len(fpr_array)\n",
    "x = fpr_array\n",
    "y = tpr_array \n",
    "sia_adam_roc = (x,y)\n",
    "sia_adam_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sia_adam_roc[0]\n",
    "y = sia_adam_roc[1]\n",
    "\n",
    "# This is the ROC curve\n",
    "plt.plot(x,y,'*')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# This is the AUC\n",
    "auc = np.trapz(y,x)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
